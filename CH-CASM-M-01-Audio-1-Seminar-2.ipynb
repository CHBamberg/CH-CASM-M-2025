{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c49dcbd",
   "metadata": {},
   "source": [
    "# Computational Analysis of Sounds and Music (CH-CASM-M)\n",
    "\n",
    "## 01 - Fundamentals of Audio Processing (1/2) Part 2\n",
    "\n",
    "**WS 2025/2026**\n",
    "\n",
    "Prof. Dr. Jakob AbeÃŸer, jakob.abesser@uni-bamberg.de\n",
    "\n",
    "Last update: 21.10.2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f84403",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "In this notebook, you will learn \n",
    " - how to load and process audio files in Python\n",
    " - how to sonify and visualize waveforms\n",
    " - how to compute and visualize the STFT, Mel Spectrogram, and CQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493c20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget\n",
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dfc180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wget\n",
    "import os\n",
    "import matplotlib\n",
    "import librosa\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as pl\n",
    "import platform\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dc1729",
   "metadata": {},
   "source": [
    "### *(Platform-independent Code)*\n",
    "\n",
    "**HINT**: if you want to write Python scripts that work on multiple platforms (like Windows, Linux etc.), you can use ```platform.platform()``` to figure out automatically, which platform your Python code is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bc099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check current platform\n",
    "print(platform.platform())\n",
    "\n",
    "# save audio in current directory\n",
    "dir_audio = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdac900",
   "metadata": {},
   "source": [
    "### Get audio example files\n",
    "\n",
    "This script loads 2 audio files that we need here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb54e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('piano.wav') or not os.path.isfile('bird.wav'):\n",
    "    for fn in ('piano.wav', 'bird.wav'):\n",
    "        wget.download('https://github.com/CHBamberg/CH-CASM-M-2025/raw/refs/heads/main/data/{}'.format(fn), \n",
    "                      out=fn, bar=None)\n",
    "else:\n",
    "    print('Files already exist!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae3865b",
   "metadata": {},
   "source": [
    "### File paths\n",
    "\n",
    "When working with multiple audio files, it is a good practice to treat directories and filenames separately and use ```os.path.join``` to combine both to absolute filenames. This command uses the correct delimiter signs for all operating systems (Windows, MacOS, Linux)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) define path to the directory that contains the audio files (WAV format)\n",
    "# TIP: under Windows, it is also recommended to use '/', e.g. 'C:/my_audio_files'\n",
    "dir_wav = ''  # here, we use the same directory as the notebook is in\n",
    "\n",
    "# this could also look like\n",
    "# dir_wav = 'c:/audio_files'\n",
    "\n",
    "# 2) create absolute path of audio file (directory + filename)\n",
    "# os.path.join takes care of the correct delimiter signs\n",
    "# - Linux / MacOSx: \"/\"\n",
    "# - Windows: \"\\\\\"\n",
    "\n",
    "fn_wav = os.path.join(dir_wav, 'bird.wav')  # original filename: 416529__inspectorj__bird-whistling-single-robin-a_2s\n",
    "assert os.path.isfile(fn_wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbbc7f2",
   "metadata": {},
   "source": [
    "### Loading audio files\n",
    "\n",
    "- first check librosa documentation: https://librosa.org/doc/main/generated/librosa.load.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3dceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) use the sample rate of the file, load stereo if needed\n",
    "x, fs = librosa.load(fn_wav)\n",
    "\n",
    "print(\"Sample vector shape:\", x.shape)  # 1D numpy array, mono\n",
    "print(\"Sample rate [Hz]\", fs)\n",
    "print(f\"Audio duration (seconds): {len(x)/fs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d229b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) you could also enforce another sample rate\n",
    "fs_fix = 44100\n",
    "x, fs = librosa.load(fn_wav, sr=fs_fix)  # in this case, the signal is upsampled to a higher sample rate\n",
    "\n",
    "print(x.shape)  # ! increase of sampling rate (upsampling) -> more samples!\n",
    "print(fs) # ! fix sample rate was used\n",
    "print(f\"Duration = {len(x)/fs} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) if you have a stereo file, you can enforce one channel audio (mono)\n",
    "# x, fs = librosa.load(fn_wav, mono=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fdf8d7",
   "metadata": {},
   "source": [
    "### Sonification\n",
    "\n",
    "Let's listen to our example audio file (birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d760c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.display(ipd.Audio(data=x, rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b8e56",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94344262",
   "metadata": {},
   "source": [
    "Our audio signal is roughly 2.06 s long. Let's extract the first 1.5 seconds of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: find the upper sample index for slicing that corresponds to a physical time of 1.5s\n",
    "sample_end = None # TASK: replace \"None\"\n",
    "x_first_1_5_s = x[:sample_end]\n",
    "print(f\"Our segment has a duration of {len(x_first_1_5_s)/fs} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f247f132",
   "metadata": {},
   "source": [
    "### Waveform Visualization\n",
    "\n",
    "Let's plot our waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce33eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(10,2))\n",
    "pl.plot(x)\n",
    "pl.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c62993a",
   "metadata": {},
   "source": [
    "**Observation**: the x-axis just shows the sample number so far, this is not informative without the sample rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee9b49",
   "metadata": {},
   "source": [
    "#### Create time axis\n",
    "\n",
    "The sample rate in Hz defines, how many audio samples exist per second. If we compute the inverse ($1/f_\\mathrm{s}$), we get the duration of each sample in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a912ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = len(x)\n",
    "print(\"Number of samples:\", number_of_samples)\n",
    "\n",
    "seconds_per_sample = None # TASK: replace \"None\" with correct command!\n",
    "print(\"Duration [seconds] of one sample\", seconds_per_sample)  # on audio sample corresponds to ~22.7 ms\n",
    "\n",
    "# let's create a numpy array with the physical time of each audio sample\n",
    "frames_in_seconds = np.arange(number_of_samples)*seconds_per_sample\n",
    "print(frames_in_seconds[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55bf25a",
   "metadata": {},
   "source": [
    "let's plot the signal again, this time with an interpretable x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27599420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pl.figure(figsize=(10,2))\n",
    "pl.plot(frames_in_seconds, x)\n",
    "pl.xlabel('Time [s]')\n",
    "pl.ylabel('Amplitude')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f3460",
   "metadata": {},
   "source": [
    "Done :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b799e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK\n",
    "# (1) open \"piano.wav\" instead\n",
    "# (2) what is the duration of the audio file (in seconds)\n",
    "# (3) create a waveform plot\n",
    "# (4) normalize the signal such that the maximum absolute value of all samples is 1\n",
    "# (5) plot the normalized waveform in a different color \n",
    "# (6) select a very short segment from an arbitrary position in the audio file (50 ms long) -> compare the waveform \n",
    "#     to the complex periodic signals discussed in the lecture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
