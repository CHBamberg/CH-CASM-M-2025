{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c49dcbd",
   "metadata": {},
   "source": [
    "# Computational Analysis of Sounds and Music (CH-CASM-M)\n",
    "\n",
    "## 02 - Fundamentals of Audio Processing (2/2)\n",
    "\n",
    "**WS 2025/2026**\n",
    "\n",
    "Prof. Dr. Jakob AbeÃŸer, jakob.abesser@uni-bamberg.de\n",
    "\n",
    "Last update: 28.10.2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f84403",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "In this notebook, you will learn \n",
    " - how to compute and visualize the STFT, Mel Spectrogram, and CQT\n",
    " - how to compute a chromagramm\n",
    " - how to compute the MFCC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493c20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dfc180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wget\n",
    "import os\n",
    "import matplotlib\n",
    "import librosa\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as pl\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdac900",
   "metadata": {},
   "source": [
    "### Get audio example files\n",
    "\n",
    "This script loads 2 audio files that we need here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb54e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('piano.wav') or not os.path.isfile('bird.wav') or not os.path.isfile('c_maj_inv_2_sounds.wav'):\n",
    "    for fn in ('piano.wav', 'bird.wav', 'c_maj_inv_2_sounds.wav'):\n",
    "        wget.download('https://github.com/CHBamberg/CH-CASM-M-2025/raw/refs/heads/main/data/{}'.format(fn), \n",
    "                      out=fn, bar=None)\n",
    "else:\n",
    "    print('Files already exist!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f247f132",
   "metadata": {},
   "source": [
    "### Waveform Visualization\n",
    "\n",
    "Let's plot our waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3dceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) use the sample rate of the file, load stereo if needed\n",
    "fs_fix = 44100\n",
    "x, fs = librosa.load('bird.wav', sr=fs_fix)  # in this case, the signal is upsampled to a higher sample rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a912ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = len(x)\n",
    "seconds_per_sample = 1/fs\n",
    "frames_in_seconds = np.arange(number_of_samples)*seconds_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27599420",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(14,3))\n",
    "pl.plot(frames_in_seconds, x)\n",
    "pl.xlabel('Time [s]')\n",
    "pl.ylabel('Amplitude')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc645181",
   "metadata": {},
   "source": [
    "### Spectrogram using Short-Time Fourier Transform (STFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c4eab",
   "metadata": {},
   "source": [
    "Let's first check the librosa documentation: https://librosa.org/doc/main/generated/librosa.stft.html?highlight=stft#librosa-stft\n",
    "\n",
    "The most important parameters are \n",
    "  - **win_length** - this is the size of our analysis window (in samples)\n",
    "  - **hop_length** - this is the hop size of our analysis window (in samples), usually this is chosen to be half the window size\n",
    "  - (**n_fft**) - this is the used \"FFT size\", which can be bigger than the **win_length** (but should be a power of two, such that the Fast Fourier Transform (FFT) algorithm can be used internally)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the STFT\n",
    "n_fft = 2048\n",
    "hop_length = 1024\n",
    "X = librosa.stft(x, n_fft=n_fft, hop_length=hop_length)  # using the default values: n_fft=2048, \n",
    "print(\"Shape of STFT:\", X.shape)  # we get n_fft//2 - 1 bins, the reason is that the STFT has a \n",
    "                                  # symmetric structure and we can discard several entries\n",
    "print(\"Data type of STFT:\", X.dtype)  # ! the STFT is complex and has a magnitude and a phase\n",
    "\n",
    "# We'll focus on the magnitude of the STFT\n",
    "S = np.abs(X)\n",
    "print(\"Shape of the magnitude spectrogram:\", S.shape)\n",
    "print(\"Data type of the magnitude spectrogram:\", S.dtype)  # ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e454aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot it\n",
    "pl.figure(figsize=(12,6))\n",
    "pl.imshow(S, aspect=\"auto\", cmap=\"Greys\")\n",
    "pl.colorbar()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ce83b3",
   "metadata": {},
   "source": [
    "There a several **problems** with this plot:\n",
    "  1. the frequency axis is flipped (lower frequencies are shown on top and higher frequencies are shown at the bottom)\n",
    "  2. only the loudest frequency components are visible  \n",
    "  3. we want the axes to show the frequency in Hz (y-axis) and the time in seconds (x-axis), at the moment, we only see the frequency bin (y-axis) of the STFT and the frame number (x-axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c378a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue 1.) use \"origin\" parameter for imshow()\n",
    "pl.figure(figsize=(12,6))\n",
    "# TASK: we need one additional parameter in the imshow command from before to vertically flip the image\n",
    "pl.colorbar()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ab54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue 2.) apply logarithmic compression to the magnitude values -> this converts the linear magnitudes to decibels (dB)\n",
    "S_dB = None # TASK check for a suitable function from librosa to implement the logarithmic scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b870c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pl.figure(figsize=(12,6))\n",
    "pl.imshow(S_dB, aspect=\"auto\", origin=\"lower\", cmap=\"Greys\")\n",
    "pl.colorbar(format='%+2.0f dB')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4403fe34",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "1.  also parts with lower magnitudes are now better visible\n",
    "2.  the value range shifts from [0, 70] to [-80, 0], this is because of the logarithmic compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue 3.) define maximum frequency, and maximum time value\n",
    "f_max = fs/2  # Nyquist frequency\n",
    "t_max = number_of_samples / fs\n",
    "print(f'Upper time limit = {f_max} s')\n",
    "print(f'Upper frequency limit = {t_max} Hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(6,4))\n",
    "# TASK add another parameter of imshow to make use of the upper time and frequency limits in our plot\n",
    "pl.xlabel('Time [s]')\n",
    "pl.ylabel('Frequency [Hz]')\n",
    "pl.colorbar(format='%+2.0f dB')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb0257d",
   "metadata": {},
   "source": [
    "**Practical Alternative**\n",
    "\n",
    "As an alternative, we can use the build-in visualization function ```specshow``` of librosa, which allows to visualize STFT spectrograms, Mel spectrograms, and others.\n",
    "\n",
    "Check the documentation for more info: https://librosa.org/doc/main/generated/librosa.display.specshow.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7006ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.display import specshow\n",
    "\n",
    "fig, ax = pl.subplots()\n",
    "# note the keyword \"mel\", which indicates that a mel frequency axis is used\n",
    "img = specshow(S_dB, x_axis='time', y_axis='hz', sr=fs, ax=ax, cmap=\"Greys\")\n",
    "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "ax.set(title='STFT Magnitude Spectrogram (specshow)')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a15326",
   "metadata": {},
   "source": [
    "### Mel-Spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c52d77",
   "metadata": {},
   "source": [
    "Let's first check the librosa documentation: https://librosa.org/doc/main/generated/librosa.feature.melspectrogram.html\n",
    "\n",
    "The most important parameters are \n",
    "  - **y** - audio sample vector ($x$)\n",
    "  - **sr** - sampling rate of the audio signal (in Hz)\n",
    "  - **n_mels** - number of Mel frequency bands (commonly: 64 or 128)\n",
    "  - **win_length** - see above (STFT)\n",
    "  - **hop_length** - see above (STFT)\n",
    "  - **n_fft** - see above (STFT)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24501885",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = librosa.feature.melspectrogram(y=x, n_fft=2048, hop_length=1024, n_mels=128)  \n",
    "print(\"Shape of Mel spectrogram:\", M.shape)  # frequency x time: we get n_mels frequency bands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b540c840",
   "metadata": {},
   "source": [
    "Let's visualize it. We want to\n",
    "1. convert the time axis (horizontal axis) to seconds (as done before for the STFT)\n",
    "2. have physical frequency values [Hz] at the vertical axis, that correspond to the 128 mel bands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843cc50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply dB compression as before\n",
    "M_dB = None # TASK use the right librosa function for logarithmic magnitude scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9302829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots()\n",
    "# note the keyword \"mel\", which indicates that a mel frequency axis is used\n",
    "img = librosa.display.specshow(M_dB, x_axis='time', y_axis='mel', sr=fs, ax=ax, cmap='viridis')\n",
    "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "ax.set(title='Mel-frequency spectrogram')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9147480d",
   "metadata": {},
   "source": [
    "### Constant-Q Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5828188b",
   "metadata": {},
   "source": [
    "Let's first check the librosa documentation: https://librosa.org/doc/main/generated/librosa.cqt.html\n",
    "\n",
    "The most important parameters are \n",
    "  - **y** - audio sample vector ($x$)\n",
    "  - **sr** - sampling rate of the audio signal (in Hz)\n",
    "  - **hop_length** - see above (STFT)\n",
    "  - **f_min** - minimum frequency (we can use the default value of 32.70 Hz which corresponds to the note C1)\n",
    "  - **n_bins** - total number of frequency bins (e.g., for a frequency resolution of one bin per semitone and 4 octaves, this would be 4 * 12 = 48)\n",
    "  - **bins_per_octave** - Logarithmic frequency resolution (frequency bins per octave, commonly: 12 or 36)\n",
    "  - **tuning** - Tuning offset (can be used if known tuning frequency of an audio recording deviates from 440 Hz) \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3f5c84",
   "metadata": {},
   "source": [
    "We'll now use a short piano recording as running example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_wav = os.path.join(dir_wav, 'piano.wav')  # original filename: 196765__xserra__piano-phrase.wav\n",
    "x, fs = librosa.load(fn_wav)\n",
    "ipd.display(ipd.Audio(data=x, rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12013e7",
   "metadata": {},
   "source": [
    "Let's compute the CQT for a frequency range of 5 octaves with a resolution of 1 bin per semitone (=12 bins per octave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc210dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_octaves = 6  # let's capture 5 octaves starting from C1\n",
    "bins_per_octave = 12  # let's choose a frequency resolution of 100 cent (= one frequency bin per semitone)\n",
    "C = np.abs(librosa.cqt(x, sr=fs, \n",
    "                       fmin=2*32.70, # C 2 as lower frequency limit\n",
    "                       n_bins=n_octaves*bins_per_octave , bins_per_octave=bins_per_octave))\n",
    "print(\"Shape of CQT:\", C.shape)  # logically, we get 60 frequency bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c709dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dB magnitude scaling\n",
    "C = librosa.amplitude_to_db(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2524944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we can use again the visualization tool provided by librosa\n",
    "fig, ax = pl.subplots()\n",
    "img = librosa.display.specshow(C, sr=fs, x_axis='time', y_axis='cqt_note', ax=ax, \n",
    "                       fmin=2*32.70)\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b36022",
   "metadata": {},
   "source": [
    "### CENS (Chroma Energy Normalize) Chroma Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f6c8f5",
   "metadata": {},
   "source": [
    "Let's first check the librosa documentation: https://librosa.org/doc/main/generated/librosa.feature.chroma_cens.html\n",
    "\n",
    "The most important parameters are \n",
    "  - **y** - audio sample vector ($x$)\n",
    "  - **sr** - sampling rate of the audio signal (in Hz)\n",
    "  - **hop_length** - see above (STFT)\n",
    "  - **f_min** - minimum frequency (we can use the default value of 32.70 Hz which corresponds to the note C1)\n",
    "  - **n_bins** - total number of frequency bins (e.g., for a frequency resolution of one bin per semitone and 4 octaves, this would be 4 * 12 = 48)\n",
    "  - **bins_per_octave** - Logarithmic frequency resolution (frequency bins per octave, commonly: 12 or 36)\n",
    "  - **tuning** - Tuning offset (can be used if known tuning frequency of an audio recording deviates from 440 Hz) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad9035",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_length=128\n",
    "cens = librosa.feature.chroma_cens(y=x, sr=fs, hop_length=hop_length, fmin=None, tuning=None, n_chroma=12, n_octaves=7, bins_per_octave=36)\n",
    "t_max = len(x) / fs\n",
    "\n",
    "pl.figure(figsize=(8,3))\n",
    "pl.imshow(cens, aspect=\"auto\", interpolation=\"None\", origin=\"lower\", extent=[0, t_max, 0, cens.shape[0]])\n",
    "# let's create an interpretable pitch axis\n",
    "pl.yticks([0.5, 2.5, 4.5, 5.5, 7.5, 9.5, 11.5], ['C', 'D', 'E', 'F', 'G', 'A', 'B'])\n",
    "pl.xlabel('Time (seconds)')\n",
    "pl.ylabel('Pitch Class')\n",
    "pl.title('CENS')\n",
    "pl.colorbar()\n",
    "pl.tight_layout()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4948465b",
   "metadata": {},
   "source": [
    "The chroma features give a nice visual summary of the pitch class distribution over time. \n",
    "\n",
    "**Note**: this is not a transcription as the pitch classes of the partial frequencies also affect this representation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68ea2a",
   "metadata": {},
   "source": [
    "### Chord Inversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a73d8a",
   "metadata": {},
   "source": [
    "Now we'll analyze a new file. It has 4 successive chords\n",
    "  - C major (root position): C E G\n",
    "  - C/E (first inversion): E G C\n",
    "  - C/G (second inversion): G C E\n",
    "  - C major (root position, one octave higher)\n",
    "  \n",
    "The chord sequence is first played using a piano, then repeated using a synthesizer sound.\n",
    "\n",
    "Here's the pianoroll view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://github.com/CHBamberg/CH-CASM-M-2025/raw/refs/heads/main/data/c_maj_inv_2_sounds.png?raw=true\"\n",
    "ipd.display(ipd.Image(url=image_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c9b253",
   "metadata": {},
   "source": [
    "Let's listen to the audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05213c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_wav = 'c_maj_inv_2_sounds.wav'\n",
    "x, fs = librosa.load(fn_wav)\n",
    "ipd.display(ipd.Audio(data=x, rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c930df89",
   "metadata": {},
   "source": [
    "Now, let's have a look to the CENS Chromagram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eb872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_length=128\n",
    "cens = librosa.feature.chroma_cens(y=x, sr=fs, hop_length=hop_length, fmin=None, tuning=None, n_chroma=12, n_octaves=7, bins_per_octave=36)\n",
    "t_max = len(x) / fs\n",
    "\n",
    "pl.figure()\n",
    "pl.imshow(cens, aspect=\"auto\", interpolation=\"None\", origin=\"lower\", extent=[0, t_max, 0, cens.shape[0]])\n",
    "# let's create an interpretable pitch axis\n",
    "pl.yticks([0.5, 2.5, 4.5, 5.5, 7.5, 9.5, 11.5], ['C', 'D', 'E', 'F', 'G', 'A', 'B'])\n",
    "pl.xlabel('Time (seconds)')\n",
    "pl.ylabel('Pitch Class')\n",
    "pl.title('CENS')\n",
    "pl.tight_layout()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf0afdf",
   "metadata": {},
   "source": [
    "What do you observe?\n",
    "\n",
    "1) Why is the chromagram pattern not changing for different inversions?\n",
    "2) Why is the chromagram pattern not changing for different instrument timbres?\n",
    "3) Can you guess where the \"transient\" (vertical) structures come frome?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1712df",
   "metadata": {},
   "source": [
    "For comparison, let's check the CQT again, here we should see how the fundamental frequency and the harmonics are increasing in frequency along the chord sequence (similar to the piano roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e849795",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_octaves = 7  # let's capture 7 octaves starting from C1\n",
    "bins_per_octave = 12  # let's choose a frequency resolution of 100 cent (= one frequency bin per semitone)\n",
    "C = np.abs(librosa.cqt(x, sr=fs, n_bins=n_octaves*bins_per_octave , bins_per_octave=bins_per_octave))\n",
    "C = librosa.amplitude_to_db(C)  # dB magnitude scaling\n",
    "fig, ax = pl.subplots()\n",
    "img = librosa.display.specshow(C, sr=fs, x_axis='time', y_axis='cqt_note', ax=ax)\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1c1dfa",
   "metadata": {},
   "source": [
    "### Mel-Frequency Cepstral Coefficients (MFCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ae681a",
   "metadata": {},
   "source": [
    "Let's first check the librosa documentation: https://librosa.org/doc/main/generated/librosa.cqt.html\n",
    "\n",
    "The most important parameters are \n",
    "  - **y** - audio sample vector ($x$)\n",
    "  - **sr** - sampling rate of the audio signal (in Hz)\n",
    "  - **n_fft** - see above (STFT)\n",
    "  - **hop_length** - see above (STFT)\n",
    "  - **n_mfcc** - Number of MFC coefficients  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compute and visualize 13 MFCCs\n",
    "n_mfcc = 20\n",
    "n_fft = 2048\n",
    "hop_length = 1024\n",
    "mf = librosa.feature.mfcc(y=x, sr=fs, S=None, n_mfcc=n_mfcc, dct_type=2, norm='ortho', lifter=0, n_fft=n_fft, hop_length=hop_length)\n",
    "pl.figure()\n",
    "pl.imshow(mf, aspect=\"auto\", origin=\"lower\", extent=[0, t_max, 0, mf.shape[0]])\n",
    "pl.xlabel('Time [s]')\n",
    "pl.ylabel('MFCC')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f757a265",
   "metadata": {},
   "source": [
    "We will use the MFCC features in the upcoming seminars as timbre feature for different classification tasks ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb5658",
   "metadata": {},
   "source": [
    "Done :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee6a92",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
